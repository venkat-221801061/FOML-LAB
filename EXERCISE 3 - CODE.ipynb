{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ac098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Simulate Data (2D binary classification)\n",
    "np.random.seed(0)\n",
    "X1 = np.random.randn(50, 2) + np.array([2, 2])\n",
    "X2 = np.random.randn(50, 2) + np.array([-2, -2])\n",
    "X = np.vstack((X1, X2))\n",
    "y = np.hstack((np.ones(50), np.zeros(50)))\n",
    "\n",
    "# 2. Add bias term (intercept)\n",
    "X_b = np.c_[np.ones((X.shape[0], 1)), X]  # shape: (100, 3)\n",
    "\n",
    "# 3. Sigmoid Function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# 4. Loss Function (Binary Cross Entropy)\n",
    "def loss(y, y_pred):\n",
    "    return -np.mean(y * np.log(y_pred + 1e-10) + (1 - y) * np.log(1 - y_pred + 1e-10))\n",
    "\n",
    "# 5. Gradient Descent\n",
    "def train(X, y, lr=0.1, epochs=1000):\n",
    "    weights = np.zeros(X.shape[1])\n",
    "    for epoch in range(epochs):\n",
    "        z = X @ weights\n",
    "        y_pred = sigmoid(z)\n",
    "        gradient = X.T @ (y_pred - y) / y.size\n",
    "        weights -= lr * gradient\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}: Loss = {loss(y, y_pred):.4f}\")\n",
    "    return weights\n",
    "\n",
    "# 6. Train the model\n",
    "weights = train(X_b, y)\n",
    "\n",
    "# 7. Predict\n",
    "def predict(X, weights):\n",
    "    return sigmoid(X @ weights) >= 0.5\n",
    "\n",
    "y_pred = predict(X_b, weights)\n",
    "accuracy = np.mean(y_pred == y)\n",
    "print(f\"\\nFinal Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# 8. Plot Decision Boundary\n",
    "x1_min, x1_max = X[:,0].min() - 1, X[:,0].max() + 1\n",
    "x2_min, x2_max = X[:,1].min() - 1, X[:,1].max() + 1\n",
    "xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max, 100),\n",
    "                       np.linspace(x2_min, x2_max, 100))\n",
    "grid = np.c_[np.ones(xx1.ravel().shape), xx1.ravel(), xx2.ravel()]\n",
    "probs = sigmoid(grid @ weights).reshape(xx1.shape)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.contourf(xx1, xx2, probs, levels=[0, 0.5, 1], alpha=0.3, colors=['blue', 'red'])\n",
    "plt.scatter(X1[:, 0], X1[:, 1], color='red', label='Class 1')\n",
    "plt.scatter(X2[:, 0], X2[:, 1], color='blue', label='Class 0')\n",
    "plt.title(\"Logistic Regression Decision Boundary\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
